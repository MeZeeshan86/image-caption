# ğŸ“· Image Caption Generator using CNN & LSTM

This repository contains a **complete AI image captioning pipeline**:
1. **Model Training** â€“ Train a CNN+LSTM model on the Flickr8k dataset to generate captions.
2. **Web App Deployment** â€“ An interactive HTML/CSS-styled app that lets users upload images and get captions instantly.

---

## âœ¨ Features
- **End-to-End Workflow** â€“ From dataset preprocessing to deployment.
- **Deep Learning Model** â€“ CNN for image feature extraction + LSTM for sequential text generation.
- **Modern Web UI** â€“ Gradient backgrounds, styled caption boxes, and responsive layout.
- **Multiple Image Formats** â€“ Supports `.jpg`, `.jpeg`, and `.png`.
- **Reusable Models** â€“ Save and load trained models for inference.

---

## ğŸ“Š Dataset
**Flickr8k Dataset**
- ~8,000 images with 5 human-written captions each.
- Captions describe scenes, objects, and actions.
- Ideal for small-scale image captioning experiments.

---

## âš™ï¸ Model Architecture
### Encoder (CNN)
- Pre-trained InceptionV3 or similar CNN model.
- Removes classification layer to output feature vectors.

### Tokenizer
- Maps words to integers for training and inference.
- Saved via `pickle` for consistent token mapping.

### Decoder (LSTM)
- Takes image features and partial captions as input.
- Predicts captions word-by-word until `<endseq>` token.

---

## ğŸ›  Training Workflow (`flickr8k-image-captioning-using-cnns-lstms.ipynb`)
1. **Data Preparation** â€“ Load images and captions, clean text, remove punctuation, lowercase words, tokenize, and pad sequences.  
2. **Feature Extraction** â€“ Extract image features with a CNN and save them for faster training.  
3. **Model Definition** â€“ Merge CNN features with embedded caption sequences and feed them into an LSTM decoder.  
4. **Training** â€“ Use categorical cross-entropy loss and monitor validation accuracy and loss.  
5. **Save Models** â€“ Store `model.keras`, `feature_extractor.keras`, and `tokenizer.pkl` for deployment.

---

## ğŸš€ App Usage (`main.py`)
```bash
# 1ï¸âƒ£ Clone the Repository
git clone https://github.com/your-username/image-caption-generator.git
cd image-caption-generator

# 2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

# 3ï¸âƒ£ Add Trained Models
# Place trained model files into the models/ directory:
models/
 â”œâ”€â”€ model.keras
 â”œâ”€â”€ feature_extractor.keras
 â””â”€â”€ tokenizer.pkl

# 4ï¸âƒ£ Run the Application
streamlit run main.py

# ğŸ“‚ Project Structure
â”œâ”€â”€ main.py                      # Web app interface + caption generation
â”œâ”€â”€ flickr8k-image-captioning... # Model training notebook
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ model.keras
â”‚   â”œâ”€â”€ feature_extractor.keras
â”‚   â””â”€â”€ tokenizer.pkl
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
